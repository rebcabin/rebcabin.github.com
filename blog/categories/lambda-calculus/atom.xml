<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Lambda Calculus | The Light Cone]]></title>
  <link href="http://rebcabin.github.com/blog/categories/lambda-calculus/atom.xml" rel="self"/>
  <link href="http://rebcabin.github.com/"/>
  <updated>2013-03-17T10:37:31-07:00</updated>
  <id>http://rebcabin.github.com/</id>
  <author>
    <name><![CDATA[Brian Beckman (rebcabin = brianbec)]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Asynchronous Lazy Lists]]></title>
    <link href="http://rebcabin.github.com/blog/2013/01/19/asynchronous-lazy-lists/"/>
    <updated>2013-01-19T22:03:00-08:00</updated>
    <id>http://rebcabin.github.com/blog/2013/01/19/asynchronous-lazy-lists</id>
    <content type="html"><![CDATA[<h2 id="synchronous-lazy-lists">SYNCHRONOUS LAZY LISTS</h2>

<p>Lazy lists make it easy to write infinite data sets without doing infinite computations. For instance, the following static method in C# will generate a lazy list that serves up all the integers (actually, all the 32-bit integers in an infinite cycle, but we quibble):</p>

<p><code>csharp A lazy list for an infinite stream of ints
public static LazyList&lt;int&gt; integers(int n)
{
    return new LazyList&lt;int&gt; {value = n, rest = () =&gt; integers(n + 1)};
}
</code></p>

<p>Notice that an instance of this <code>LazyList</code> type has two properties (or fields, if you prefer): a <code>value</code> and a <code>rest</code>, which is a function, (lambda expression) that, when invoked, will produce the rest of the infinite stream. That’s the essence of the technique: keep the infinite stuff in a function, recursively, and pick out values only when you need them. </p>

<p>Next is my implementation of the <code>LazyList</code> class.  Of course, I could use <a href="http://msdn.microsoft.com/en-us/library/dd642331.aspx">C#’s built-in <code>Lazy</code> type</a>, but I am, on purpose, doing the details myself for deeper understanding and exploration. We’re going to morph these into task-based LazyLists that produce the downstream values asynchronously:</p>

<p>``` csharp Implementation of the LazyList class
public class LazyList<t>
{
    public T value;
    public Func&lt;LazyList<t>&gt; rest;</t></t></p>

<pre><code>public T nth(int n)
{
    return 
        (n &lt;= 1) ? 
        value : 
        rest().nth(n - 1);
} } ```
</code></pre>

<p>In addition to the properties already mentioned, I’ve included an <code>nth</code> method that walks up the lazy list in O(n) time to get the <code>n</code>-th item (without the <a href="http://stackoverflow.com/questions/7102520/does-c-sharp-do-tail-recursion">tail-recursion optimization</a>, this code will also consume O(n) space on the stack).  This is not designed to fetch the <code>n</code>-th item directly, as is possible with some <a href="http://en.wikipedia.org/wiki/Spigot_algorithm">spigot algorithms</a>, and it might be very interesting to explore spigots using lazy techniques in C#, but perhaps another time.</p>

<p>Next is a little more meat on the bones: the obligatory factorial:</p>

<p><code>csharp A LazyList that produces factorials
public static LazyList&lt;int&gt; factorials(int n)
{
    return new LazyList&lt;int&gt; 
    {
        value = (n &lt;= 1) ? 1 : n * factorials(n - 1).value, 
        rest = () =&gt; factorials(n + 1)
    };
}
</code></p>

<p>This one uses recursion in the production of <code>value</code>.  There are two uses of recursion: <code>value</code> recursively uses prior values, <code>rest</code> recursively produces future values. This is pretty neat. Both uses of recursion are completely synchronous and all this code runs on one thread.</p>

<p>We could go on to fibonaccis and more exotic streams; we could anonymize these for remoting, memoize them for efficiency, as explained <a href="http://rebcabin.github.com/blog/2012/12/08/anonymous-memoizing-lazy-lists/">an earlier post on this blog</a>; but that’s not where we’re going today.</p>

<p>One last thing before going <code>async</code>, and thats for a bit of code that exercises the above, using <a href="http://www.linqpad.net">LinqPad</a>:</p>

<p>``` csharp Exercising the LazyLists
void Main()
{
    var k1 = integers(1);
    // Expect 5
    k1.nth(5).Dump();</p>

<pre><code>var k2 = factorials(1);
// Expect 120
k2.nth(5).Dump();

// A hint for what's coming up next
AsyncMain(); } ```
</code></pre>

<p>Much more with synchronous lazy streams can be found in this wonderful paper: 
<a href="http://www.cs.dartmouth.edu/~doug/music.ps.gz">Music of the Streams by Doug McIlroy</a>. But on to asynchrony for us.</p>

<h2 id="asynchronous-lazy-lists-with-task">ASYNCHRONOUS LAZY LISTS WITH TASK</h2>

<p>Let’s start with ‘what-we-want’ in AsyncMain:</p>

<p>``` csharp AsyncMain
public static async void AsyncMain()
{
    DumpThreadId(“Async main, k3: “); <br />
    var k3 = asyncIntegers(1);
    (await k3.nth(5)).Dump();</p>

<pre><code>DumpThreadId("Async main, k4: ");
var k4 = asyncFactorials(1);
(await k4.nth(5)).Dump();

var z0 = (await Task.Run(() =&gt;
{   DumpThreadId("Anonymous task: ");
    Thread.Sleep(ran.Next(200));
    return 42;
}));

DumpThreadId("Async main, z0: "); } ```
</code></pre>

<p>We made a new main because <a href="http://msdn.microsoft.com/en-us/library/vstudio/hh156513.aspx">we needed it to be <code>async</code></a> and we can’t mark the regular <code>Main</code> as <code>async</code>.  What we want, here, is to <code>await</code> the computation of <code>asyncIntegers</code> and <code>asyncFactorials</code> in the body of <code>AsyncMain</code>.  This can cause various threads to jump around in our code, so we’re careful to print thread id’s after every <code>await</code> and in the body of every lambda expression that runs asynchronously in 
a task, via the following static method:</p>

<p><code>csharp How to dump a thread id
public static void DumpThreadId(string msg = "")
{   System.Threading.Thread.CurrentThread.ManagedThreadId.Dump(msg + "Thread Id");
}
</code></p>

<p>We’ll also insert a number of artificial random delays to try to entice the thread scheduler to send different threads through our code.  None of these <code>Sleeps</code> are part of the algorithm at all; they’re here to induce interesting behavior.</p>

<p>Now look at the implementation of <code>asyncIntegers</code>:</p>

<p><code>csharp asyncIntegers
public static AsyncList&lt;int&gt; asyncIntegers(int n)
{   return new AsyncList&lt;int&gt; 
    {   value = n, 
        rest = () =&gt; 
        {   DumpThreadId("AsyncIntegers, rest: ");
            Thread.Sleep(ran.Next(200));
            return asyncIntegers(n + 1);
        }
    };
}
</code></p>

<p>Looks just like the implementation of lazy integers.  The variable <code>k3 = asyncIntegers(5)</code> in <code>AsyncMain</code> must be of type <code>AsyncList</code>.   The deeper differences are in <code>nth</code>, the method we use to walk the lazy list:</p>

<p>``` csharp AsyncList
public class AsyncList<t>
{   public T value;
    public Func&lt;AsyncList<t>&gt; rest;</t></t></p>

<pre><code>public async Task&lt;T&gt; nth(int n)
{   return
        (n &lt;= 1) ?
        await (Task.Run(() =&gt; 
        {   DumpThreadId("AsyncList, nth: ");
            return value;
        })) :
        await Task.Run(() =&gt; 
        {   Thread.Sleep(ran.Next(200));
            return rest().nth(n - 1);
        });
} } ```
</code></pre>

<p>We use only one facet of <a href="http://msdn.microsoft.com/en-us/library/vstudio/dd321424.aspx">the multifaceted <code>Task</code> class</a>. The rule we use is that <code>Task.Run</code>, when given a <code>Func&lt;T&gt;</code>, produces a <code>Task&lt;T&gt;</code>. Awaiting a <code>Task&lt;T&gt;</code> prduces a <code>T</code>.  So, except for the routing through <code>Task</code>, it looks like invoking a <code>Func&lt;T&gt;</code> to produce a <code>T</code>. This seems like a minimal intrusion of task-ness on our original lazy-list design.</p>

<p>Look at the first branch of <code>nth</code>, when <code>n &lt;= 1</code>. We <code>await</code> a <code>Task.Run</code> of a <code>Func&lt;T&gt;</code> that produces <code>value</code>, so the result of the <code>await</code> is of type <code>T</code>, the type of <code>value</code>.  This <code>T</code> gets returned through an <code>async</code> method, namely <code>nth</code>, so it gets converted back into a <code>Task&lt;T&gt;</code> on the way out.  In the body of <code>AsyncMain</code>, where we are calling <code>nth</code>, we <code>await</code> this <code>Task&lt;T&gt;</code>, getting back a <code>T</code> in the end. </p>

<p><code>T</code>’s become <code>Task&lt;T&gt;</code> when run under <code>Task.Run</code> or when returned from any <code>async</code> method that would otherwise produce a <code>T</code>.  <code>Task&lt;T&gt;</code>’s become <code>T</code>’s when <code>awaited</code> (there’s a monad in here somewhere, but that’s for another time, too).</p>

<p>On the other branch of <code>nth</code>, The new <code>rest</code> will walk up the lazy list just as before, only awaiting the value of <code>rest().nth(n-1)</code> to get a <code>T</code>; and returning it through the <code>async</code> to get a <code>Task&lt;T&gt;</code> on the way out (EDIT: thanks to Brian Grunkmeyer for a bug fix here).</p>

<p>On both branches, <code>nth</code> is of type <code>Task&lt;T&gt;</code>, just what we need to <code>await</code> on in the caller to get <code>T</code>’s. </p>

<p>Here is the more meaty async factorial, which doesn’t differ in any interesting way from the lazy-list factorial:</p>

<p><code>csharp asyncFactorial
public static AsyncList&lt;int&gt; asyncFactorials(int n)
{   return new AsyncList&lt;int&gt; 
    {   value = (n &lt;= 1) ? 1 : n * asyncFactorials(n - 1).value, 
        rest = () =&gt; 
        {   DumpThreadId("AsyncFactorials, rest: ");
            Thread.Sleep(ran.Next(200));
            return asyncFactorials(n + 1);
        }
    };
}
</code></p>

<p>It may take a few tries to get a lot of thread variety: the thread-pool scheduler seems to have hints from your code and tries to reuse the same thread whenever it can.  But eventually, you can get a trace like the following that shows various thread moving around these tasks. </p>

<p>```
5
120
Async main, k3: Thread Id 
16 </p>

<p>AsyncIntegers, rest: Thread Id 
22 </p>

<p>AsyncIntegers, rest: Thread Id 
37 </p>

<p>AsyncIntegers, rest: Thread Id 
37 </p>

<p>AsyncIntegers, rest: Thread Id 
37 </p>

<p>AsyncList, nth: Thread Id 
37 </p>

<p>5
Async main, k4: Thread Id 
37 </p>

<p>AsyncFactorials, rest: Thread Id 
37 </p>

<p>AsyncFactorials, rest: Thread Id 
37 </p>

<p>AsyncFactorials, rest: Thread Id 
37 </p>

<p>AsyncFactorials, rest: Thread Id 
37 </p>

<p>AsyncList, nth: Thread Id 
26 </p>

<p>120
Anonymous task: Thread Id 
37 </p>

<p>Async main, z0: Thread Id 
37 
```</p>

<p>A gist for this LINQPad script can be found here: <a href="https://gist.github.com/4580491">https://gist.github.com/4580491</a>.  </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Anonymous Memoizing Lazy Lists]]></title>
    <link href="http://rebcabin.github.com/blog/2012/12/08/anonymous-memoizing-lazy-lists/"/>
    <updated>2012-12-08T20:41:00-08:00</updated>
    <id>http://rebcabin.github.com/blog/2012/12/08/anonymous-memoizing-lazy-lists</id>
    <content type="html"><![CDATA[<p>A vastly prettier version of this blog can be found 
in the CDF file here: <a href="https://dl.dropbox.com/u/1997638/LazyLambda003.cdf">https://dl.dropbox.com/u/1997638/LazyLambda003.cdf</a>. Wolfram’s free CDF reader is found at <a href="http://www.wolfram.com/cdf-player/">http://www.wolfram.com/cdf-player/</a>.</p>

<p>One reason to care about anonymized computations is that naming things costs memory, and it’s the kind of memory that lasts from one computation to another – session memory. Naming things means writing definitions and storing them in tables for access in later computations. Building up big memoization tables as definitions can cost a LOT of memory. We can save this cost if we can avoid naming things, storing information in function parameters that only last the lifetime of a single computation.</p>

<h2 id="non-anonymous-lazy-lists">NON-ANONYMOUS LAZY LISTS</h2>

<p>Lazy lists are a handy way of expressing infinite data streams. A typical lazy list might look like the following:</p>

<p><code>
In[1]:= integersFrom[n_] := {n, integersFrom[n + 1] &amp;}
</code></p>

<p>Calling <code>integersFrom</code> with some numerical argument produces a list in curly braces, the first element of which is that numerical argument and the second element of which is a delayed list in the form of a nullary function – a function of no parameters. That’s what the <code>&amp;</code> means: “the expression to my left is a function.” We’re doing Lisp-style lists, which are pairs of values and lists.</p>

<p>The list in the second slot of the lazy list won’t be automatically evaluated – we must manually invoke the function that produces it when we want the results. That is the essence of lazy computation. Lazy languages like Haskell can decide when you need the results and just sidestep the explicit wrapping in a nullary function and the manual invocation. With eager or strict languages like Mathematica, we must do the invocations manually. But that’s good, because we can see more clearly what’s going on. </p>

<p>In our lazy lists, the second item will always be a nullary function.</p>

<p>Start peeling integers off such a structure one at a time. <code>integersFrom[0]</code> will be a lazy list of integers starting from 0, and 
<code>[[1]]</code> will pick the first element from the resulting list:</p>

<p><code>
In[2]:= integersFrom[0][[1]]
Out[2]= 0
</code></p>

<p>If we pick the second element from <code>integersFrom[0]</code>, that will be a nullary function that produces the next lazy list. Manually invoke the function by appending <code>[]</code> – invocation brackets containing no arguments – and then pick off the first element of the result to get the next integer.</p>

<p><code>
In[3]:= integersFrom[0][[2]][][[1]]
Out[3]= 1
</code></p>

<p>And so on:</p>

<p><code>
In[4]:= integersFrom[0][[2]][][[2]][][[1]]
Out[4]= 2
</code></p>

<p>A pattern emerges that we can capture in some operators. <code>Value</code> just picks the first element of a lazy list, and <code>next</code> picks the second element – the nullary function – and invokes it on no arguments:</p>

<p>```
In[5]:= value[stream<em>] := stream[[1]];
next[stream</em>] := stream[[2]][];</p>

<p>In[7]:= value@integersFrom[0]
Out[7]= 0</p>

<p>In[8]:= value@next@integersFrom[0]
Out[8]= 1</p>

<p>In[9]:= value@next@next@integersFrom[0]
Out[9]= 2
```</p>

<p>Improve the <code>value</code> operator so we can ask for the <code>n</code> th value, recursively:</p>

<p>```
In[10]:= ClearAll[value];
value[stream<em>, n</em>: 1] :=
 If[n &lt;= 1,
  stream[[1]],
  value[next[stream], n - 1]]</p>

<p>In[12]:= value[integersFrom[1], 26]
Out[12]= 26
```</p>

<p>Let’s see a few values by mapping over a list of inputs:</p>

<p><code>
In[13]:= value[integersFrom[1], #] &amp; /@ {1, 2, 3, 4, 5, 10, 15, 20}
Out[13]= {1, 2, 3, 4, 5, 10, 15, 20}
</code></p>

<p>We don’t need <code>next</code> any more – only <code>value</code> used it. Inline it in the body of <code>value</code>:</p>

<p><code>
In[14]:= ClearAll[next, value];
value[stream_, n_: 1] :=
  If[n &lt;= 1,
   stream[[1]],
   value[stream[[2]][], n - 1]];
</code></p>

<p>As an aside, an efficient implementation of <code>value</code> requires either the tail-recursion optimization in the interpreter or a re-expression in iterative form, which can be done semi-automatically.</p>

<p>Write another lazy list as follows:</p>

<p>```
In[16]:= ClearAll[fibonaccis];
fibonaccis[n_] :=
 {If[n &lt;= 1,
   1,
   value[fibonaccis[n - 1]] + value[fibonaccis[n - 2]]],
  fibonaccis[n + 1] &amp;
  }</p>

<p>In[18]:= Timing[value[fibonaccis[1], 15]]
Out[18]= {0.024130, 987}
```</p>

<p>Of course, this is exponentially inefficient, as are all non-memoizing recursive fibonaccis. Fib of 15 is already painful, and fib of 150 is unthinkable. This can be mitigated as follows:</p>

<p>```
In[19]:= ClearAll[fibonaccis];
fibonaccis[n_] :=
 fibonaccis[n] =
  {If[n &lt;= 1,
    1,
    value[fibonaccis[n - 1]] + value[fibonaccis[n - 2]]],
   fibonaccis[n + 1] &amp;
   }</p>

<p>In[21]:= fibonaccis[#] &amp; /@ {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20}
Out[21]= {{1, fibonaccis[1 + 1] &amp;}, {2, fibonaccis[2 + 1] &amp;}, {3, 
  fibonaccis[3 + 1] &amp;}, {5, fibonaccis[4 + 1] &amp;}, {8, 
  fibonaccis[5 + 1] &amp;}, {13, fibonaccis[6 + 1] &amp;}, {21, 
  fibonaccis[7 + 1] &amp;}, {34, fibonaccis[8 + 1] &amp;}, {55, 
  fibonaccis[9 + 1] &amp;}, {89, fibonaccis[10 + 1] &amp;}, {987, 
  fibonaccis[15 + 1] &amp;}, {10946, fibonaccis[20 + 1] &amp;}}</p>

<p>In[22]:= Timing[value[fibonaccis[1], 150]]
Out[22]= {0.001997, 16130531424904581415797907386349}
```</p>

<p>This is a well-known Mathematica idiom for building a memo table by side effect. The memo table consists of explicit, specific point-values for <code>fibonaccis</code>, which the general <code>fibonaccis</code> – the one depending on a single parameter <code>n_</code> – creates on-the-fly. Subsequent references to <code>fibonaccis</code>` at known inputs will do a quick lookup on the specific values and avoid the exponential recomputation. </p>

<p>This is non-anonymous programming on steroids – everything is built up inside the named object <code>fibonaccis</code>, but it gives us great speed at the expense of memory. But this is global memory in Mathematica’s global brain. When we’re done with the calculation, we have modified the session state of Mathematica and not left things the way we found them. In some scenarios, this would not be allowed. We must find some other way to evaluate recursive formulas without requiring session state – using only ephemeral memory such as stack frames that go away when our result is achieved.</p>

<p>Let’s get rid of the named functions and then even get rid of the named memo table so we can have decent performance on our recursive evaluations.</p>

<h2 id="anonymize">ANONYMIZE</h2>

<p>The mother of all anonymizers is the Y combinator:</p>

<p><code>
In[23]:= Y = (subjectCode \[Function] (g \[Function] g@g)
     [precursor \[Function] subjectCode
       [n \[Function] precursor[precursor][n]]]);
</code></p>

<p>Without going into how it works, Y is a function that takes another function as an argument. That other function takes an argument <code>k</code> and produces a function of <code>n</code>. The function of <code>n</code> can call <code>k</code> as if <code>k</code> were a recursive definition of the function of <code>n</code>. The function of <code>n</code> can be applied to workhorse arguments, that is, to arguments of the subject code.</p>

<p>In practice, Y is easy to use: just apply it to a function of <code>k</code> that produces a function of <code>n</code> that internally calls <code>k</code>, then apply the result to the desired <code>n</code>.  </p>

<p>Here is the lazy list of integers, this time starting at 1, without using the name of the lazy list inside the definition of the lazy list: s1 does not refer to s1:</p>

<p>```
In[24]:= ClearAll[s1];
s1 = Y[k [Function] n [Function]
      {n, k[n + 1] &amp;}
    ][1];</p>

<p>In[26]:= value[s1]
Out[26]= 1
```</p>

<p>We feed to Y a function of <code>k</code>. That function of <code>k</code> produces a function of <code>n</code>. That function of <code>n</code> produces a list in curly braces. The first element of that list is the value <code>n</code>, and the second element of that list is a delayed call of <code>k</code> on the next value, <code>n+1</code>. <code>s1</code> is thus a lazy list of all the integers, just defined without reference to any names but parameters. No global storage needed, no session state. </p>

<p>Let’s map calls of <code>value[s1,#]&amp;</code> over a sequence of inputs to consicely show it off multiple times:</p>

<p><code>
In[27]:= value[s1, #] &amp; /@ {1, 2, 3, 4, 26}
Out[27]= {1, 2, 3, 4, 26}
</code></p>

<p>Now, on to an anonymized lazy list of fibonaccis:</p>

<p><code>
In[28]:= ClearAll[s2];
s2 = Y[k \[Function] n \[Function]
      {If[n &lt;= 1,
        1,
        value[k[n - 1]] + value[k[n - 2]]],
       k[n + 1] &amp;}
    ][1];
</code></p>

<p>This one is still slow:</p>

<p><code>
In[30]:= Timing[value[s2, #] &amp; /@ {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20}]
Out[30]= {0.883336, {1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 987, 10946}}
</code></p>

<p>It takes about a second to produce <code>fib[20]</code>, and higher values become intolerable. We would never get to an absurd input like 150.</p>

<h2 id="memoize">MEMOIZE</h2>

<p>How can we speed it up without defining point values in some named object? By defining point values in an un-named object, of course! Un-named objects are best modeled in Mathematica as lists of rules, one for each point-like input. We’ll need to pass that around in the argument list of <code>k</code>, and the easiest way to do that is to make <code>n</code>, the argument of <code>k</code>, a regular Mathematica list to contain both a value and an anonymous dictionary. </p>

<p>We’ll get to this form in a few steps. First, just change <code>n</code> so that it’s a list rather than an integer. This change spreads a lot of indexing around the body of <code>k</code>, so we want to make sure we get that right before proceeding:</p>

<p>```
In[31]:= ClearAll[s3];
s3 = Y[k [Function] n [Function]
      {If[n[[1]] &lt;= 1,
        {1},
        {value[k[{n[[1]] - 1}]][[1]] +
          value[k[{n[[1]] - 2}]][[1]]}
        ],
       k[{n[[1]] + 1}] &amp;}
    ][{1}];</p>

<p>In[33]:= Timing[value[s3, #] &amp; /@ {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20}]
Out[33]= {1.145393, {{1}, {2}, {3}, {5}, {8}, {13}, {21}, {34}, {55}, {89}, {987}, \
{10946}}}
```</p>

<p>Now add a second element – an empty list – to <code>n</code>, but ignore it in the code, just to make sure we get all the shaping correct. We must modify six places where arguments to k are constructed:</p>

<p>```
In[34]:= ClearAll[s4];
s4 = Y[k [Function] n [Function]
      {If[n[[1]] &lt;= 1,
        {1, {}},(* 
        modification 1 <em>)
        {value[k[{n[[1]] - 1, {}}]][[1]] + (</em> 
          modification 2 <em>)
          value[k[{n[[1]] - 2, {}}]][[1]],
         (</em> modification 3 <em>)
         {}} (</em> modification 4 <em>)
        ],
       k[{n[[1]] + 1, {}}] &amp;} (</em> 
    modification 5 <em>)
    ][{1, {}}]; (</em> modification 6 *)</p>

<p>In[36]:= Timing[value[s4, #] &amp; /@ {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20}]
Out[36]= {1.214176, {{1, {}}, {2, {}}, {3, {}}, {5, {}}, {8, {}}, {13, {}}, {21, {}}, \
{34, {}}, {55, {}}, {89, {}}, {987, {}}, {10946, {}}}}
```</p>

<p>Now replace the internal constant empty lists with references to the second slot of <code>n</code>, where we will eventually store the dictionary:</p>

<p>```
In[37]:= ClearAll[s5];
s5 = Y[k [Function] n [Function]
      {If[n[[1]] &lt;= 1,
        {1, n[[2]]},
        {value[k[{n[[1]] - 1, n[[2]]}]][[1]] +
          value[k[{n[[1]] - 2, n[[2]]}]][[1]],
         n[[2]]}
        ],
       k[{n[[1]] + 1, n[[2]]}] &amp;}
    ][{1, {}}];</p>

<p>In[39]:= Timing[value[s5, #] &amp; /@ {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20}]
Out[39]= {1.308497, {{1, {}}, {2, {}}, {3, {}}, {5, {}}, {8, {}}, {13, {}}, {21, {}}, \
{34, {}}, {55, {}}, {89, {}}, {987, {}}, {10946, {}}}}
```</p>

<p>We’re now ready to promote that second part of <code>n</code> into a dictionary – same as anonymous object, same as list of rules – for fast lookups. Let’s take the convention that if a key is not present in the dictionary, we produce <code>Null</code>, and make a few helper functions:</p>

<p><code>
In[40]:= ClearAll[lookup, add];
lookup[dict_, key_] := key /. dict;
add[dict_, key_, value_] :=
  With[{trial = lookup[dict, key]},
   If[trial =!= Null,
    dict,
    If[Head[dict] === Dispatch,
     Dispatch[Prepend[dict[[1]], key -&gt; value]],
     Dispatch[Prepend[dict, key -&gt; value]]]]];
</code></p>

<p><code>Add</code> converts the dictionary into a hash table by applying the Mathematica built-in <code>Dispatch</code> to it. This is similar to what relational databases do when computing joins – creates a temporary hash table and uses it. Before adding a new rule to the table, add must check whether the input table is already a hash table since the original list of rules is stored in slot 1 of a hash table. <code>Add</code> can only add a rule to a list of rules, not to a hash table, but <code>add</code> can regenerate a new hash table in linear time. This is a potential hidden quadratic in this code since the hash table will be created over and over again. It does not seem to be a serious problem, here, likely overwhelmed by other overheads.</p>

<p>Now add the code to store computed values in the anonymous object. We must modify the initial input from <code>{1, {}}</code> to <code>{1, {_-&gt;Null}}</code> so that the starting dictionary has the default rule.</p>

<p>```
In[43]:= ClearAll[s6];
s6 = Y[k [Function] n [Function]
      Module[{valToStore, dict = n[[2]]},
       {If[n[[1]] &lt;= 1,
         {1, dict},
         valToStore =
          value[k[{n[[1]] - 1, dict}]][[1]] +
           value[k[{n[[1]] - 2, dict}]][[1]];
         dict = add[dict, n[[1]], valToStore];
         {valToStore, dict}
         ],
        k[{n[[1]] + 1, dict}] &amp;}]
    ][{1, {_ -&gt; Null}}];</p>

<p>In[45]:= Timing[value[s6, #] &amp; /@ {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20}]</p>

<p>Out[45]= {6.912630,
{{1,{<em>-&gt;Null}},
{2,{2-&gt;2,</em>-&gt;Null}},
{3,{3-&gt;3,2-&gt;2,<em>-&gt;Null}},
{5,{4-&gt;5,3-&gt;3,2-&gt;2,</em>-&gt;Null}},
{8,Dispatch[{5-&gt;8,4-&gt;5,3-&gt;3,2-&gt;2,<em>-&gt;Null},-DispatchTables-]},
{13,Dispatch[{6-&gt;13,5-&gt;8,4-&gt;5,3-&gt;3,2-&gt;2,</em>-&gt;Null},-DispatchTables-]},
{21,Dispatch[{7-&gt;21,6-&gt;13,5-&gt;8,4-&gt;5,3-&gt;3,2-&gt;2,<em>-&gt;Null},-DispatchTables-]},
{34,Dispatch[{8-&gt;34,7-&gt;21,6-&gt;13,5-&gt;8,4-&gt;5,3-&gt;3,2-&gt;2,</em>-&gt;Null},-DispatchTables-]},
{55,Dispatch[{9-&gt;55,8-&gt;34,7-&gt;21,6-&gt;13,5-&gt;8,4-&gt;5,3-&gt;3,2-&gt;2,<em>-&gt;Null},-DispatchTables-]},
{89,Dispatch[{10-&gt;89,9-&gt;55,8-&gt;34,7-&gt;21,6-&gt;13,5-&gt;8,4-&gt;5,3-&gt;3,2-&gt;2,</em>-&gt;Null},-DispatchTables-]},
{987,Dispatch[{15-&gt;987,14-&gt;610,13-&gt;377,12-&gt;233,11-&gt;144,10-&gt;89,9-&gt;55,8-&gt;34,7-&gt;21,6-&gt;13,5-&gt;8,4-&gt;5,3-&gt;3,2-&gt;2,<em>-&gt;Null},-DispatchTables-]},
{10946,Dispatch[{20-&gt;10946,19-&gt;6765,18-&gt;4181,17-&gt;2584,16-&gt;1597,15-&gt;987,14-&gt;610,13-&gt;377,12-&gt;233,11-&gt;144,10-&gt;89,9-&gt;55,8-&gt;34,7-&gt;21,6-&gt;13,5-&gt;8,4-&gt;5,3-&gt;3,2-&gt;2,</em>-&gt;Null},-DispatchTables-]}}}</p>

<p>```</p>

<p>Now add code to do lookups</p>

<p><code>
In[46]:= ClearAll[s7];
s7 = Y[k \[Function] n \[Function]
      Module[{valToStore, dict = n[[2]]},
       {If[n[[1]] &lt;= 1,
         {1, dict},
         valToStore =
          With[{
            v1 = lookup[dict, n[[1]] - 1],
            v2 = lookup[dict, n[[2]] - 2]},
           If[v1 =!= Null, v1,
             value[k[{n[[1]] - 1, dict}]][[1]]] +
            If[v2 =!= Null, v2,
             value[k[{n[[1]] - 2, dict}]][[1]]]];
         dict = add[dict, n[[1]], valToStore];
         {valToStore, dict}
         ],
        k[{n[[1]] + 1, dict}] &amp;}]
    ][{1, {_ -&gt; Null}}];
</code></p>

<p>Now our regular example is much faster and an otherwise inconceivable computation such as <code>fib[150]</code> can be done in a reasonable time. </p>

<p>```
In[48]:= Timing[
 value[s7, #][[1]] &amp; /@ {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20}]
Out[48]= {0.068064, {1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 987, 10946}}</p>

<p>In[49]:= Block[{$RecursionLimit = 2000}, Timing[value[s7, 150][[1]]]]
Out[49]= {1.308640, 16130531424904581415797907386349}
```</p>

<h2 id="conclusion">CONCLUSION</h2>

<p>Many improvements can be made to this, such as getting rid of the mutable variables in the <code>Module</code> by a monadic bind and refactoring the code for readability. However, we have shown a general technique for creating lazy memoizing lists without introducing names or session state into an evaluator or interpreter.</p>
]]></content>
  </entry>
  
</feed>
